{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "<h1>Model Without Using Training DataSet</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Installing all the required packages</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from pandas) (1.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (1.23.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk) (2022.8.17)\n",
      "Requirement already satisfied: tqdm in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: sklearn in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from sklearn) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from scikit-learn->sklearn) (1.23.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from scikit-learn->sklearn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from seaborn) (1.23.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from seaborn) (3.5.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from seaborn) (1.9.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.37.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk>=3.1->textblob) (2022.8.17)\n",
      "Requirement already satisfied: joblib in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\porallapradhyumna\\.conda\\envs\\sentiment\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.5)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install nltk\n",
    "!pip install sklearn\n",
    "!pip install seaborn\n",
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing basic required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the TASK file and adding the heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv('TASK1_Tweets.csv', on_bad_lines='skip',names=['TWEETS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasmine Strange shares a message of hope durin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I gotta fight these allergies in public to mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/57NBQ2XQsG  On Easter please reme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lenibriscoe I have a cute one made from recyc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Told my Mom we should start to work from home ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This will I fear continue as it seemed like it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TWEETS\n",
       "0  \\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...\n",
       "1  Jasmine Strange shares a message of hope durin...\n",
       "2  I gotta fight these allergies in public to mak...\n",
       "3  https://t.co/57NBQ2XQsG  On Easter please reme...\n",
       "4  @lenibriscoe I have a cute one made from recyc...\n",
       "5  Told my Mom we should start to work from home ...\n",
       "6  \\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...\n",
       "7        We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8\n",
       "8  QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...\n",
       "9  This will I fear continue as it seemed like it..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cleaning the data set</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\PorallaPradhyumna\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PorallaPradhyumna\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\PorallaPradhyumna\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PorallaPradhyumna\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\PorallaPradhyumna\\AppData\\Roaming\\nltk_data..\n",
      "[nltk_data]     .\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#downloading nltk pre-sets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def clean(text):\n",
    "    tweet = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                       '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', text)\n",
    "    tweet = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", text)\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    text = word_tokenize(text)\n",
    "    all_stopwords = stopwords.words('english')\n",
    "    all_stopwords.remove('not')\n",
    "    text = [ps.stem(word) for word in text if not word in set(all_stopwords) and len(word)>3]\n",
    "    text = pos_tag(text)\n",
    "    #text = [wordnet_lemmatizer.lemmatize(word,pos_dict.get(tag[0])) for word,tag in text ]\n",
    "    return text\n",
    "\n",
    "data_set['Cleaned_TWEETS'] =  data_set['TWEETS'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETS</th>\n",
       "      <th>Cleaned_TWEETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...</td>\n",
       "      <td>[(suck, VBN), (social, JJ), (distanc, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasmine Strange shares a message of hope durin...</td>\n",
       "      <td>[(jasmin, NN), (strang, NN), (share, NN), (mes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I gotta fight these allergies in public to mak...</td>\n",
       "      <td>[(fight, NN), (allergi, VBZ), (public, JJ), (m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/57NBQ2XQsG  On Easter please reme...</td>\n",
       "      <td>[(http, NN), (xqsg, NNP), (easter, NN), (pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lenibriscoe I have a cute one made from recyc...</td>\n",
       "      <td>[(lenibrisco, NN), (cute, NN), (made, VBD), (r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Told my Mom we should start to work from home ...</td>\n",
       "      <td>[(told, JJ), (start, NN), (work, NN), (home, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8</td>\n",
       "      <td>[(deep, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...</td>\n",
       "      <td>[(alguien, NN), (expliqu, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This will I fear continue as it seemed like it...</td>\n",
       "      <td>[(thi, NNS), (fear, VBP), (continu, JJ), (seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TWEETS  \\\n",
       "0  \\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...   \n",
       "1  Jasmine Strange shares a message of hope durin...   \n",
       "2  I gotta fight these allergies in public to mak...   \n",
       "3  https://t.co/57NBQ2XQsG  On Easter please reme...   \n",
       "4  @lenibriscoe I have a cute one made from recyc...   \n",
       "5  Told my Mom we should start to work from home ...   \n",
       "6  \\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...   \n",
       "7        We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8   \n",
       "8  QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...   \n",
       "9  This will I fear continue as it seemed like it...   \n",
       "\n",
       "                                      Cleaned_TWEETS  \n",
       "0         [(suck, VBN), (social, JJ), (distanc, NN)]  \n",
       "1  [(jasmin, NN), (strang, NN), (share, NN), (mes...  \n",
       "2  [(fight, NN), (allergi, VBZ), (public, JJ), (m...  \n",
       "3  [(http, NN), (xqsg, NNP), (easter, NN), (pleas...  \n",
       "4  [(lenibrisco, NN), (cute, NN), (made, VBD), (r...  \n",
       "5  [(told, JJ), (start, NN), (work, NN), (home, N...  \n",
       "6                                                 []  \n",
       "7                                       [(deep, NN)]  \n",
       "8                     [(alguien, NN), (expliqu, NN)]  \n",
       "9  [(thi, NNS), (fear, VBP), (continu, JJ), (seem...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lemmatizing the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "\n",
    "def wordnet_lemmatizer_clean(text):\n",
    "    lemma = []\n",
    "    for word,tag in text:\n",
    "        tag = pos_dict.get(tag[0])\n",
    "        if word.lower() not in stopwords.words('english'):\n",
    "            if not tag:\n",
    "                lemma.append(word)\n",
    "            else:\n",
    "                lemma.append(wordnet_lemmatizer.lemmatize(word,tag))\n",
    "\n",
    "    return ' '.join(lemma)\n",
    "\n",
    "data_set['Lemmatized_TWEETS'] =  data_set['Cleaned_TWEETS'].apply(wordnet_lemmatizer_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETS</th>\n",
       "      <th>Cleaned_TWEETS</th>\n",
       "      <th>Lemmatized_TWEETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...</td>\n",
       "      <td>[(suck, VBN), (social, JJ), (distanc, NN)]</td>\n",
       "      <td>suck social distanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasmine Strange shares a message of hope durin...</td>\n",
       "      <td>[(jasmin, NN), (strang, NN), (share, NN), (mes...</td>\n",
       "      <td>jasmin strang share messag hope life covid mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I gotta fight these allergies in public to mak...</td>\n",
       "      <td>[(fight, NN), (allergi, VBZ), (public, JJ), (m...</td>\n",
       "      <td>fight allergi public make sure peopl think corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/57NBQ2XQsG  On Easter please reme...</td>\n",
       "      <td>[(http, NN), (xqsg, NNP), (easter, NN), (pleas...</td>\n",
       "      <td>http xqsg easter plea rememb poor desol covid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lenibriscoe I have a cute one made from recyc...</td>\n",
       "      <td>[(lenibrisco, NN), (cute, NN), (made, VBD), (r...</td>\n",
       "      <td>lenibrisco cute make recycl sari silk friend n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Told my Mom we should start to work from home ...</td>\n",
       "      <td>[(told, JJ), (start, NN), (work, NN), (home, N...</td>\n",
       "      <td>told start work home corona el work offic know...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8</td>\n",
       "      <td>[(deep, NN)]</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...</td>\n",
       "      <td>[(alguien, NN), (expliqu, NN)]</td>\n",
       "      <td>alguien expliqu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This will I fear continue as it seemed like it...</td>\n",
       "      <td>[(thi, NNS), (fear, VBP), (continu, JJ), (seem...</td>\n",
       "      <td>thi fear continu seem like season last winter ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TWEETS  \\\n",
       "0  \\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...   \n",
       "1  Jasmine Strange shares a message of hope durin...   \n",
       "2  I gotta fight these allergies in public to mak...   \n",
       "3  https://t.co/57NBQ2XQsG  On Easter please reme...   \n",
       "4  @lenibriscoe I have a cute one made from recyc...   \n",
       "5  Told my Mom we should start to work from home ...   \n",
       "6  \\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...   \n",
       "7        We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8   \n",
       "8  QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...   \n",
       "9  This will I fear continue as it seemed like it...   \n",
       "\n",
       "                                      Cleaned_TWEETS  \\\n",
       "0         [(suck, VBN), (social, JJ), (distanc, NN)]   \n",
       "1  [(jasmin, NN), (strang, NN), (share, NN), (mes...   \n",
       "2  [(fight, NN), (allergi, VBZ), (public, JJ), (m...   \n",
       "3  [(http, NN), (xqsg, NNP), (easter, NN), (pleas...   \n",
       "4  [(lenibrisco, NN), (cute, NN), (made, VBD), (r...   \n",
       "5  [(told, JJ), (start, NN), (work, NN), (home, N...   \n",
       "6                                                 []   \n",
       "7                                       [(deep, NN)]   \n",
       "8                     [(alguien, NN), (expliqu, NN)]   \n",
       "9  [(thi, NNS), (fear, VBP), (continu, JJ), (seem...   \n",
       "\n",
       "                                   Lemmatized_TWEETS  \n",
       "0                                suck social distanc  \n",
       "1  jasmin strang share messag hope life covid mus...  \n",
       "2  fight allergi public make sure peopl think corona  \n",
       "3  http xqsg easter plea rememb poor desol covid ...  \n",
       "4  lenibrisco cute make recycl sari silk friend n...  \n",
       "5  told start work home corona el work offic know...  \n",
       "6                                                     \n",
       "7                                               deep  \n",
       "8                                    alguien expliqu  \n",
       "9  thi fear continu seem like season last winter ...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the Sentiment Scores for the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def get_sentiment_scores(text):\n",
    "    return {\"polarity\":TextBlob(text).sentiment.polarity,\"subjectivity\": TextBlob(text).sentiment.subjectivity}\n",
    "\n",
    "data_set['Sentiment_Scores'] =  data_set['Lemmatized_TWEETS'].apply(get_sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETS</th>\n",
       "      <th>Cleaned_TWEETS</th>\n",
       "      <th>Lemmatized_TWEETS</th>\n",
       "      <th>Sentiment_Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...</td>\n",
       "      <td>[(suck, VBN), (social, JJ), (distanc, NN)]</td>\n",
       "      <td>suck social distanc</td>\n",
       "      <td>{'polarity': 0.03333333333333333, 'subjectivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasmine Strange shares a message of hope durin...</td>\n",
       "      <td>[(jasmin, NN), (strang, NN), (share, NN), (mes...</td>\n",
       "      <td>jasmin strang share messag hope life covid mus...</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I gotta fight these allergies in public to mak...</td>\n",
       "      <td>[(fight, NN), (allergi, VBZ), (public, JJ), (m...</td>\n",
       "      <td>fight allergi public make sure peopl think corona</td>\n",
       "      <td>{'polarity': 0.25, 'subjectivity': 0.477777777...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/57NBQ2XQsG  On Easter please reme...</td>\n",
       "      <td>[(http, NN), (xqsg, NNP), (easter, NN), (pleas...</td>\n",
       "      <td>http xqsg easter plea rememb poor desol covid ...</td>\n",
       "      <td>{'polarity': -0.4, 'subjectivity': 0.6}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lenibriscoe I have a cute one made from recyc...</td>\n",
       "      <td>[(lenibrisco, NN), (cute, NN), (made, VBD), (r...</td>\n",
       "      <td>lenibrisco cute make recycl sari silk friend n...</td>\n",
       "      <td>{'polarity': 0.5, 'subjectivity': 1.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Told my Mom we should start to work from home ...</td>\n",
       "      <td>[(told, JJ), (start, NN), (work, NN), (home, N...</td>\n",
       "      <td>told start work home corona el work offic know...</td>\n",
       "      <td>{'polarity': 0.5, 'subjectivity': 0.7}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8</td>\n",
       "      <td>[(deep, NN)]</td>\n",
       "      <td>deep</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...</td>\n",
       "      <td>[(alguien, NN), (expliqu, NN)]</td>\n",
       "      <td>alguien expliqu</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This will I fear continue as it seemed like it...</td>\n",
       "      <td>[(thi, NNS), (fear, VBP), (continu, JJ), (seem...</td>\n",
       "      <td>thi fear continu seem like season last winter ...</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.2833333333...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TWEETS  \\\n",
       "0  \\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...   \n",
       "1  Jasmine Strange shares a message of hope durin...   \n",
       "2  I gotta fight these allergies in public to mak...   \n",
       "3  https://t.co/57NBQ2XQsG  On Easter please reme...   \n",
       "4  @lenibriscoe I have a cute one made from recyc...   \n",
       "5  Told my Mom we should start to work from home ...   \n",
       "6  \\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...   \n",
       "7        We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8   \n",
       "8  QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...   \n",
       "9  This will I fear continue as it seemed like it...   \n",
       "\n",
       "                                      Cleaned_TWEETS  \\\n",
       "0         [(suck, VBN), (social, JJ), (distanc, NN)]   \n",
       "1  [(jasmin, NN), (strang, NN), (share, NN), (mes...   \n",
       "2  [(fight, NN), (allergi, VBZ), (public, JJ), (m...   \n",
       "3  [(http, NN), (xqsg, NNP), (easter, NN), (pleas...   \n",
       "4  [(lenibrisco, NN), (cute, NN), (made, VBD), (r...   \n",
       "5  [(told, JJ), (start, NN), (work, NN), (home, N...   \n",
       "6                                                 []   \n",
       "7                                       [(deep, NN)]   \n",
       "8                     [(alguien, NN), (expliqu, NN)]   \n",
       "9  [(thi, NNS), (fear, VBP), (continu, JJ), (seem...   \n",
       "\n",
       "                                   Lemmatized_TWEETS  \\\n",
       "0                                suck social distanc   \n",
       "1  jasmin strang share messag hope life covid mus...   \n",
       "2  fight allergi public make sure peopl think corona   \n",
       "3  http xqsg easter plea rememb poor desol covid ...   \n",
       "4  lenibrisco cute make recycl sari silk friend n...   \n",
       "5  told start work home corona el work offic know...   \n",
       "6                                                      \n",
       "7                                               deep   \n",
       "8                                    alguien expliqu   \n",
       "9  thi fear continu seem like season last winter ...   \n",
       "\n",
       "                                    Sentiment_Scores  \n",
       "0  {'polarity': 0.03333333333333333, 'subjectivit...  \n",
       "1             {'polarity': 0.0, 'subjectivity': 0.0}  \n",
       "2  {'polarity': 0.25, 'subjectivity': 0.477777777...  \n",
       "3            {'polarity': -0.4, 'subjectivity': 0.6}  \n",
       "4             {'polarity': 0.5, 'subjectivity': 1.0}  \n",
       "5             {'polarity': 0.5, 'subjectivity': 0.7}  \n",
       "6             {'polarity': 0.0, 'subjectivity': 0.0}  \n",
       "7             {'polarity': 0.0, 'subjectivity': 0.4}  \n",
       "8             {'polarity': 0.0, 'subjectivity': 0.0}  \n",
       "9  {'polarity': 0.0, 'subjectivity': 0.2833333333...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lable the Tweets with Positive, Negative and Neutral according to the scores</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lables(scores):\n",
    "    polaritiy = scores['polarity']\n",
    "    if polaritiy<0:\n",
    "        return \"Negative\"\n",
    "    elif polaritiy==0:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "data_set['Predicted_lables'] =  data_set['Sentiment_Scores'].apply(Lables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEETS</th>\n",
       "      <th>Cleaned_TWEETS</th>\n",
       "      <th>Lemmatized_TWEETS</th>\n",
       "      <th>Sentiment_Scores</th>\n",
       "      <th>Predicted_lables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...</td>\n",
       "      <td>[(suck, VBN), (social, JJ), (distanc, NN)]</td>\n",
       "      <td>suck social distanc</td>\n",
       "      <td>{'polarity': 0.03333333333333333, 'subjectivit...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jasmine Strange shares a message of hope durin...</td>\n",
       "      <td>[(jasmin, NN), (strang, NN), (share, NN), (mes...</td>\n",
       "      <td>jasmin strang share messag hope life covid mus...</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I gotta fight these allergies in public to mak...</td>\n",
       "      <td>[(fight, NN), (allergi, VBZ), (public, JJ), (m...</td>\n",
       "      <td>fight allergi public make sure peopl think corona</td>\n",
       "      <td>{'polarity': 0.25, 'subjectivity': 0.477777777...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://t.co/57NBQ2XQsG  On Easter please reme...</td>\n",
       "      <td>[(http, NN), (xqsg, NNP), (easter, NN), (pleas...</td>\n",
       "      <td>http xqsg easter plea rememb poor desol covid ...</td>\n",
       "      <td>{'polarity': -0.4, 'subjectivity': 0.6}</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@lenibriscoe I have a cute one made from recyc...</td>\n",
       "      <td>[(lenibrisco, NN), (cute, NN), (made, VBD), (r...</td>\n",
       "      <td>lenibrisco cute make recycl sari silk friend n...</td>\n",
       "      <td>{'polarity': 0.5, 'subjectivity': 1.0}</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Told my Mom we should start to work from home ...</td>\n",
       "      <td>[(told, JJ), (start, NN), (work, NN), (home, N...</td>\n",
       "      <td>told start work home corona el work offic know...</td>\n",
       "      <td>{'polarity': 0.5, 'subjectivity': 0.7}</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8</td>\n",
       "      <td>[(deep, NN)]</td>\n",
       "      <td>deep</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.4}</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...</td>\n",
       "      <td>[(alguien, NN), (expliqu, NN)]</td>\n",
       "      <td>alguien expliqu</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.0}</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This will I fear continue as it seemed like it...</td>\n",
       "      <td>[(thi, NNS), (fear, VBP), (continu, JJ), (seem...</td>\n",
       "      <td>thi fear continu seem like season last winter ...</td>\n",
       "      <td>{'polarity': 0.0, 'subjectivity': 0.2833333333...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              TWEETS  \\\n",
       "0  \\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x91\\xf0\\x9f\\x98\\x...   \n",
       "1  Jasmine Strange shares a message of hope durin...   \n",
       "2  I gotta fight these allergies in public to mak...   \n",
       "3  https://t.co/57NBQ2XQsG  On Easter please reme...   \n",
       "4  @lenibriscoe I have a cute one made from recyc...   \n",
       "5  Told my Mom we should start to work from home ...   \n",
       "6  \\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x94\\xf0\\x9f\\x92\\x...   \n",
       "7        We are all in deep doo doo \\xf0\\x9f\\x8d\\xb8   \n",
       "8  QUE ALGUIEN EXPLIQUE \\xf0\\x9f\\x93\\xa2\\xf0\\x9f\\...   \n",
       "9  This will I fear continue as it seemed like it...   \n",
       "\n",
       "                                      Cleaned_TWEETS  \\\n",
       "0         [(suck, VBN), (social, JJ), (distanc, NN)]   \n",
       "1  [(jasmin, NN), (strang, NN), (share, NN), (mes...   \n",
       "2  [(fight, NN), (allergi, VBZ), (public, JJ), (m...   \n",
       "3  [(http, NN), (xqsg, NNP), (easter, NN), (pleas...   \n",
       "4  [(lenibrisco, NN), (cute, NN), (made, VBD), (r...   \n",
       "5  [(told, JJ), (start, NN), (work, NN), (home, N...   \n",
       "6                                                 []   \n",
       "7                                       [(deep, NN)]   \n",
       "8                     [(alguien, NN), (expliqu, NN)]   \n",
       "9  [(thi, NNS), (fear, VBP), (continu, JJ), (seem...   \n",
       "\n",
       "                                   Lemmatized_TWEETS  \\\n",
       "0                                suck social distanc   \n",
       "1  jasmin strang share messag hope life covid mus...   \n",
       "2  fight allergi public make sure peopl think corona   \n",
       "3  http xqsg easter plea rememb poor desol covid ...   \n",
       "4  lenibrisco cute make recycl sari silk friend n...   \n",
       "5  told start work home corona el work offic know...   \n",
       "6                                                      \n",
       "7                                               deep   \n",
       "8                                    alguien expliqu   \n",
       "9  thi fear continu seem like season last winter ...   \n",
       "\n",
       "                                    Sentiment_Scores Predicted_lables  \n",
       "0  {'polarity': 0.03333333333333333, 'subjectivit...         Positive  \n",
       "1             {'polarity': 0.0, 'subjectivity': 0.0}          Neutral  \n",
       "2  {'polarity': 0.25, 'subjectivity': 0.477777777...         Positive  \n",
       "3            {'polarity': -0.4, 'subjectivity': 0.6}         Negative  \n",
       "4             {'polarity': 0.5, 'subjectivity': 1.0}         Positive  \n",
       "5             {'polarity': 0.5, 'subjectivity': 0.7}         Positive  \n",
       "6             {'polarity': 0.0, 'subjectivity': 0.0}          Neutral  \n",
       "7             {'polarity': 0.0, 'subjectivity': 0.4}          Neutral  \n",
       "8             {'polarity': 0.0, 'subjectivity': 0.0}          Neutral  \n",
       "9  {'polarity': 0.0, 'subjectivity': 0.2833333333...          Neutral  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving The Final Preditcion File in \"Analysed_DataSet.csv\"</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set.to_csv(\"Analysed_DataSet.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sentiment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4319fc3644636bf62a9dcd1febd23cb6ef2152f0da1830f7ca2f60a76ab725e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
